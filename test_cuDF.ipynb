{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import timeit\n",
    "\n",
    "import cupy as cp\n",
    "cp.random.seed(12)\n",
    "\n",
    "#### Portions of this were borrowed and adapted from the\n",
    "#### cuDF cheatsheet, existing cuDF documentation,\n",
    "#### and 10 Minutes to Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import cupy as cp\n",
    "import cudf\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "from cuml.common.device_selection import using_device_type, set_global_device_type, get_global_device_type\n",
    "\n",
    "# import dask_cudf\n",
    "# from dask.distributed import Client, wait\n",
    "# from dask_cuda import LocalCUDACluster\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster = LocalCUDACluster(n_workers=1, threads_per_worker=512)\n",
    "# client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a \"coordinate\" dataframe\n",
    "n_points = 400000\n",
    "#df = cudf.DataFrame()\n",
    "\n",
    "point_cloud = torch.cuda.FloatTensor(n_points, 3).uniform_()\n",
    "\n",
    "# df['x'] = point_cloud[:, 0]\n",
    "# df['y'] = point_cloud[:, 1]\n",
    "# df['z'] = point_cloud[:, 2]\n",
    "\n",
    "# Generate random data for the DataFrame\n",
    "random_data = np.array(point_cloud.cpu())\n",
    "\n",
    "# Create the cudf.DataFrame\n",
    "df = cudf.DataFrame(random_data, columns=[\"X\", \"Y\", \"Z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf = dask_cudf.from_cudf(df, npartitions=1)\n",
    "# ddf.head()\n",
    "\n",
    "# ddf = ddf.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.datasets import make_blobs\n",
    "from time import perf_counter\n",
    "\n",
    "# # Generate random data for the DataFrame\n",
    "# random_data2 = np.random.rand(n_points, 3)\n",
    "\n",
    "# # Create the cudf.DataFrame\n",
    "# fit_df = cudf.DataFrame(random_data2, columns=[\"X\", \"Y\", \"Z\"])\n",
    "\n",
    "# fit model\n",
    "model = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "model.fit(df)\n",
    "\n",
    "# start_time = perf_counter()\n",
    "\n",
    "# # get 3 nearest neighbors\n",
    "# distances_fit, indices_fit = model.kneighbors(fit_df)\n",
    "\n",
    "# end_time = perf_counter()\n",
    "# print(f\"Average execution time with blobs: {end_time-start_time:.6f} seconds\")\n",
    "\n",
    "\n",
    "start_time = perf_counter()\n",
    "\n",
    "# get 3 nearest neighbors\n",
    "distances1, indices1 = model.kneighbors(df)\n",
    "\n",
    "end_time = perf_counter()\n",
    "print(f\"Average execution time with common data: {end_time-start_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_df.shape == df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def autoSearchAlgorithm(df_input):\n",
    "    # Create a cuML NearestNeighbors model\n",
    "    nn = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "\n",
    "    # Compute the Dask DataFrame\n",
    "    # ddf_computed = ddf.compute()\n",
    "\n",
    "    # Fit the model with the input data\n",
    "    nn.fit(df_input)\n",
    "\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    # Get the nearest neighbors\n",
    "    distances2, indices2 = nn.kneighbors(df_input)\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"auto Execution time: {execution_time} seconds\")\n",
    "    # print(indices.compute())\n",
    "\n",
    "    return distances2, indices2, execution_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances2, indices2, execution_time_auto = autoSearchAlgorithm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices1.head() == indices2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbcSearchAlgorithm(df_input):\n",
    "    # Create a cuML NearestNeighbors model\n",
    "    nn2 = NearestNeighbors(n_neighbors=n_neighbors, algorithm='rbc')\n",
    "\n",
    "    # Fit the model with the input data\n",
    "    nn2.fit(df_input)\n",
    "\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    # Get the nearest neighbors\n",
    "    distances3, indices3 = nn2.kneighbors(df_input)\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"rbc Execution time: {execution_time} seconds\")\n",
    "\n",
    "    return distances3, indices3, execution_time\n",
    "\n",
    "distances3, indices3, execution_time_rbc = rbcSearchAlgorithm(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices2.head() == indices3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ivfflatSearchAlgorithm(df_input):\n",
    "    # Create a cuML NearestNeighbors model\n",
    "    nn3 = NearestNeighbors(n_neighbors=n_neighbors, algorithm='ivfflat')\n",
    "\n",
    "    # Fit the model with the input data\n",
    "    nn3.fit(df_input)\n",
    "\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    # Get the nearest neighbors\n",
    "    distances4, indices4 = nn3.kneighbors(df_input)\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"ivfflat Execution time: {execution_time} seconds\")\n",
    "\n",
    "    return distances4, indices4, execution_time\n",
    "\n",
    "distances4, indices4, execution_time_ivfflat = ivfflatSearchAlgorithm(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indices3.head() == indices4.head())\n",
    "print(indices4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pointops\n",
    "\n",
    "def knn_query_pointopsv1(n_neighbors_input, point_cloud_input, n_points_input):\n",
    "    n_points_tensor = torch.cuda.FloatTensor([n_points_input])\n",
    "\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    reference_index, _ = pointops.knn_query(n_neighbors_input, point_cloud_input, n_points_tensor)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    reference_index_cpu = reference_index.cpu()\n",
    "\n",
    "    # print(reference_index)\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"C++ PointopsV1 KNN Execution time: {execution_time} seconds\")\n",
    "    # print(reference_index.shape)\n",
    "\n",
    "    return reference_index_cpu, execution_time\n",
    "\n",
    "reference_index_cpu, execution_time_pointopsv1 = knn_query_pointopsv1(n_neighbors, point_cloud, n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(indices1))\n",
    "print(type(reference_index_cpu))\n",
    "\n",
    "# Assuming you have a cuDF DataFrame (cudf_df) and a PyTorch Tensor (torch_tensor)\n",
    "# Extract the data from the cuDF DataFrame\n",
    "indices1_data = indices1.to_pandas().values\n",
    "\n",
    "# Convert the cuDF data to a PyTorch Tensor\n",
    "torch_indices1_data = torch.tensor(indices1_data).to(torch.int32)\n",
    "\n",
    "# Compare the content element-wise\n",
    "are_equal = torch.equal(torch_indices1_data, reference_index_cpu)\n",
    "\n",
    "if are_equal:\n",
    "    print(\"The content of the cuDF DataFrame and PyTorch Tensor is equal.\")\n",
    "else:\n",
    "    print(\"The content differs between the cuDF DataFrame and PyTorch Tensor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare element-wise equality\n",
    "elementwise_equal = torch.eq(torch_indices1_data, reference_index_cpu)\n",
    "\n",
    "# Find indices where elements are different (i.e., where elementwise_equal is False)\n",
    "differing_indices = torch.nonzero(~elementwise_equal)\n",
    "\n",
    "\n",
    "print(differing_indices)\n",
    "print(torch_indices1_data)\n",
    "print(reference_index_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pointops2 import pointops2 as newerPointOps2\n",
    "\n",
    "def knn_query_pointopsv2(n_neighbors_input, point_cloud_input, n_points_input):\n",
    "    n_points_tensor = torch.cuda.FloatTensor([n_points_input])\n",
    "\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    reference_index, _ = newerPointOps2.knnquery(n_neighbors_input, point_cloud_input, None, n_points_tensor, n_points_tensor)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    reference_index_cpu2 = reference_index.cpu()\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"C++ PointopsV2 KNN Execution time: {execution_time} seconds\")\n",
    "    # print(reference_index)\n",
    "\n",
    "    return reference_index_cpu2, execution_time\n",
    "\n",
    "reference_index_cpu2, execution_time_pointopsv2 = knn_query_pointopsv2(n_neighbors, point_cloud, n_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(indices1))\n",
    "print(type(reference_index_cpu2))\n",
    "\n",
    "# Assuming you have a cuDF DataFrame (cudf_df) and a PyTorch Tensor (torch_tensor)\n",
    "# Extract the data from the cuDF DataFrame\n",
    "indices1_data = indices1.to_pandas().values\n",
    "\n",
    "# Convert the cuDF data to a PyTorch Tensor\n",
    "torch_indices1_data = torch.tensor(indices1_data).to(torch.int32)\n",
    "\n",
    "# Compare the content element-wise\n",
    "are_equal = torch.equal(torch_indices1_data, reference_index_cpu2)\n",
    "\n",
    "if are_equal:\n",
    "    print(\"The content of the cuDF DataFrame and PyTorch Tensor is equal.\")\n",
    "else:\n",
    "    print(\"The content differs between the cuDF DataFrame and PyTorch Tensor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare element-wise equality\n",
    "elementwise_equal = torch.eq(torch_indices1_data, reference_index_cpu2)\n",
    "\n",
    "# Find indices where elements are different (i.e., where elementwise_equal is False)\n",
    "differing_indices2 = torch.nonzero(~elementwise_equal)\n",
    "\n",
    "\n",
    "print(differing_indices2)\n",
    "print(torch_indices1_data)\n",
    "print(reference_index_cpu2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(differing_indices2, differing_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a cuML NearestNeighbors model\n",
    "# nn4 = NearestNeighbors(n_neighbors=n_neighbors, algorithm='ivfpq')\n",
    "# # Compute the Dask DataFrame\n",
    "# ddf_computed = ddf.compute()\n",
    "\n",
    "# start_time = timeit.default_timer()\n",
    "\n",
    "\n",
    "\n",
    "# # Fit the model with the input data\n",
    "# nn4.fit(ddf_computed)\n",
    "\n",
    "# # Get the nearest neighbors\n",
    "# distances, indices = nn4.kneighbors(ddf_computed)\n",
    "\n",
    "# end_time = timeit.default_timer()\n",
    "# execution_time = end_time - start_time\n",
    "# print(f\"ivfflat Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Execution times of each function\n",
    "execution_times = [execution_time_auto, execution_time_rbc, execution_time_ivfflat, execution_time_pointopsv1, execution_time_pointopsv2]\n",
    "\n",
    "# Function names\n",
    "function_names = ['autoSearchAlgorithm', 'rbcSearchAlgorithm', 'ivfflatSearchAlgorithm', 'knn_query_pointopsv1', 'knn_query_pointopsv2']\n",
    "\n",
    "# Number of n_points\n",
    "n_points_used = n_points\n",
    "\n",
    "# Plotting the execution times\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(function_names, execution_times)\n",
    "plt.xlabel('Function')\n",
    "plt.ylabel('Execution Time (seconds)')\n",
    "plt.title(f'Execution Time of Functions (n_points = {n_points_used})')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of n_points values\n",
    "n_points_list = [500000, 1000000, 1500000, 2000000, 2500000, 3000000, 3500000, 4000000, 4500000, 5000000, 5500000] # Do not use a number above 5500000 if your GPU Memory is 16GB\n",
    "\n",
    "# Lists to store execution times for each function\n",
    "execution_times_auto = []\n",
    "execution_times_rbc = []\n",
    "execution_times_ivfflat = []\n",
    "execution_times_pointopsv1 = []\n",
    "execution_times_pointopsv2 = []\n",
    "\n",
    "# Loop over n_points values\n",
    "for n_points in n_points_list:\n",
    "\n",
    "    print(f\"Current n_points: {n_points}\")\n",
    "\n",
    "    # Generate random data for the DataFrame\n",
    "    point_cloud = torch.cuda.FloatTensor(n_points, 3).uniform_()\n",
    "\n",
    "    # Generate random data for the DataFrame\n",
    "    random_data = np.array(point_cloud.cpu())\n",
    "\n",
    "    # Create the cudf.DataFrame\n",
    "    df = cudf.DataFrame(random_data, columns=[\"X\", \"Y\", \"Z\"])\n",
    "\n",
    "    # Call the functions and measure execution time\n",
    "    distances_auto, indices_auto, execution_time_auto = autoSearchAlgorithm(df)\n",
    "    distances_rbc, indices_rbc, execution_time_rbc = rbcSearchAlgorithm(df)\n",
    "    distances_ivfflat, indices_ivfflat, execution_time_ivfflat = ivfflatSearchAlgorithm(df)\n",
    "    reference_index_cpu, execution_time_pointopsv1 = knn_query_pointopsv1(n_neighbors, point_cloud, n_points)\n",
    "    reference_index_cpu2, execution_time_pointopsv2 = knn_query_pointopsv2(n_neighbors, point_cloud, n_points)\n",
    "\n",
    "    # Append execution times to the respective lists\n",
    "    execution_times_auto.append(execution_time_auto)\n",
    "    execution_times_rbc.append(execution_time_rbc)\n",
    "    execution_times_ivfflat.append(execution_time_ivfflat)\n",
    "    execution_times_pointopsv1.append(execution_time_pointopsv1)\n",
    "    execution_times_pointopsv2.append(execution_time_pointopsv2)\n",
    "\n",
    "# Create a DataFrame to store the execution times\n",
    "execution_times_df = pd.DataFrame({\n",
    "    'n_points': n_points_list,\n",
    "    'autoSearchAlgorithm': execution_times_auto,\n",
    "    'rbcSearchAlgorithm': execution_times_rbc,\n",
    "    'ivfflatSearchAlgorithm': execution_times_ivfflat,\n",
    "    'knn_query_pointopsv1': execution_times_pointopsv1,\n",
    "    'knn_query_pointopsv2': execution_times_pointopsv2\n",
    "})\n",
    "\n",
    "# Plotting the execution times\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(execution_times_df['n_points'], execution_times_df['autoSearchAlgorithm'], label='autoSearchAlgorithm')\n",
    "plt.plot(execution_times_df['n_points'], execution_times_df['rbcSearchAlgorithm'], label='rbcSearchAlgorithm')\n",
    "plt.plot(execution_times_df['n_points'], execution_times_df['ivfflatSearchAlgorithm'], label='ivfflatSearchAlgorithm')\n",
    "plt.plot(execution_times_df['n_points'], execution_times_df['knn_query_pointopsv1'], label='knn_query_pointopsv1')\n",
    "plt.plot(execution_times_df['n_points'], execution_times_df['knn_query_pointopsv2'], label='knn_query_pointopsv2')\n",
    "plt.xlabel('n_points')\n",
    "plt.ylabel('Execution Time (seconds)')\n",
    "plt.title('Execution Time Comparison for Different n_points')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_times_df.to_csv('execution_times.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the CSV file\n",
    "execution_times_df = pd.read_csv('execution_times.csv')\n",
    "\n",
    "# Plotting the execution times\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(execution_times_df['n_points'], execution_times_df['autoSearchAlgorithm'], label='autoSearchAlgorithm')\n",
    "plt.plot(execution_times_df['n_points'], execution_times_df['rbcSearchAlgorithm'], label='rbcSearchAlgorithm')\n",
    "plt.plot(execution_times_df['n_points'], execution_times_df['ivfflatSearchAlgorithm'], label='ivfflatSearchAlgorithm')\n",
    "plt.plot(execution_times_df['n_points'], execution_times_df['knn_query_pointopsv1'], label='knn_query_pointopsv1')\n",
    "plt.plot(execution_times_df['n_points'], execution_times_df['knn_query_pointopsv2'], label='knn_query_pointopsv2')\n",
    "plt.xlabel('n_points')\n",
    "plt.ylabel('Execution Time (seconds)')\n",
    "plt.title('Execution Time Comparison for Different n_points')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointcept_py_3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
